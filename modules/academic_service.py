#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ ëª¨ë“ˆ
ê¸°ë³¸ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•œ í•œêµ­ì–´ í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤
"""

import os
import sys
import json
import time
from typing import Dict, List, Optional, Any
from pathlib import Path

# ëª¨ë“ˆ import
from .model_service import ModelService
from .document_manager import DocumentManager
from .retrieval_interface import create_semantic_retrieval_interface
from .context_builder import create_context_builder
from .academic_analyzer import AcademicAnalyzer
from .transcript_summarizer import TranscriptSummarizer

class AcademicCounselingService:
    """í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path: str = None):
        """
        í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            model_path: ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸ê°’: None, ìë™ ê°ì§€)
        """
        print("ğŸ“ í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        
        # ê¸°ë³¸ ì„¤ì •
        if model_path is None:
            model_path = "C:/Users/user/Desktop/DeepLearning/LLM/Qwen2.5-14B-Instruct"
        self.model_path = model_path
        self.transcript_data = None
        self.analysis_result = None
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.model_service = None
        self.document_manager = None
        self.retrieval_interface = None
        self.context_builder = None
        self.academic_analyzer = None
        self.summarizer = None
        
        # ì´ˆê¸°í™” ìˆ˜í–‰
        self._initialize_components()
        
        print("í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def _initialize_components(self):
        """í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”"""
        try:
            # 1. ëª¨ë¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            print("ëª¨ë¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
            self.model_service = ModelService(self.model_path)
            
            # ëª¨ë¸ ë¡œë”©
            if not self.model_service.load_model():
                raise RuntimeError("ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
            
            # 2. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            print("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
            from sentence_transformers import SentenceTransformer
            self.embedder = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
            if hasattr(self.model_service, 'device') and self.model_service.device == "cuda":
                self.embedder = self.embedder.to("cuda")
                print("ì„ë² ë”© ëª¨ë¸ì„ CUDAë¡œ ì´ë™ ì™„ë£Œ")
            
            # 3. ë¬¸ì„œ ê´€ë¦¬ì ì´ˆê¸°í™”
            print("ë¬¸ì„œ ê´€ë¦¬ì ì´ˆê¸°í™” ì¤‘...")
            self.document_manager = DocumentManager()
            
            # 4. ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™” (ì„ë² ë”© ëª¨ë¸ ì „ë‹¬)
            print("ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
            self.retrieval_interface = create_semantic_retrieval_interface(self.embedder)
            
            # 5. ì»¨í…ìŠ¤íŠ¸ ë¹Œë” ì´ˆê¸°í™”
            print("ì»¨í…ìŠ¤íŠ¸ ë¹Œë” ì´ˆê¸°í™” ì¤‘...")
            self.context_builder = create_context_builder()
            
            # 6. í•™ì‚¬ ë¶„ì„ê¸° ì´ˆê¸°í™”
            print("í•™ì‚¬ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
            self.academic_analyzer = AcademicAnalyzer()
            
            # 7. ì„±ì í‘œ ìš”ì•½ê¸° ì´ˆê¸°í™”
            print("ì„±ì í‘œ ìš”ì•½ê¸° ì´ˆê¸°í™” ì¤‘...")
            self.summarizer = TranscriptSummarizer()
            
            # 8. RAG ë°ì´í„°ì…‹ ë¡œë”©
            print("RAG ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
            self._load_rag_dataset()
            
            # 9. ì„±ì í‘œ ë°ì´í„° ë¡œë“œ
            self._load_transcript_data()
            
        except Exception as e:
            print(f"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _load_rag_dataset(self):
        """RAG ë°ì´í„°ì…‹ ë¡œë”©"""
        try:
            rag_dir = "C:/Users/user/Desktop/DeepLearning/LLM/rag_dataset"  
            if os.path.exists(rag_dir):
                # ë¬¸ì„œ ê´€ë¦¬ìë¥¼ í†µí•´ RAG ë°ì´í„°ì…‹ ë¡œë”©
                success = self.document_manager.load_rag_dataset(rag_dir)
                
                if success:
                    # ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ì— ë¬¸ì„œ ì¶”ê°€
                    documents, metadata = self.document_manager.get_documents()
                    self.retrieval_interface.add_documents(documents, metadata)
                    print(f"RAG ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")
                else:
                    print("RAG ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨")
            else:
                print(f"RAG ë°ì´í„°ì…‹ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {rag_dir}")
        except Exception as e:
            print(f"RAG ë°ì´í„°ì…‹ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _load_transcript_data(self):
        """ì„±ì í‘œ ë°ì´í„° ë¡œë“œ"""
        try:
            # ì›ë˜ ê²½ë¡œë¡œ ë³µêµ¬
            transcript_path = Path("C:/Users/user/Desktop/DeepLearning/LLM/Project_AI/outputs/transcripts_100/12190002_b6d48c.json")
            if transcript_path.exists():
                with open(transcript_path, 'r', encoding='utf-8') as f:
                    self.transcript_data = json.load(f)
                print("ì„±ì í‘œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
                
                # í•™ì‚¬ ë¶„ì„ ìˆ˜í–‰
                self.analysis_result = self.academic_analyzer.analyze_graduation_requirements(
                    self.transcript_data
                )
                print("ì¡¸ì—… ìš”ê±´ ë¶„ì„ ì™„ë£Œ")
                
                # ì„±ì í‘œ ìš”ì•½ ì •ë³´ë¥¼ RAGì— ì¶”ê°€
                self._add_transcript_to_rag()
            else:
                print(f"ì„±ì í‘œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {transcript_path}")
        except Exception as e:
            print(f"ì„±ì í‘œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _add_transcript_to_rag(self):
        """ì„±ì í‘œ ìš”ì•½ ì •ë³´ë¥¼ RAGì— ì¶”ê°€"""
        try:
            if self.transcript_data:
                # ì„±ì í‘œ ìš”ì•½ ë¬¸ì„œ ìƒì„±
                docs = self.summarizer.create_multiple_rag_docs(self.transcript_data)
                
                # ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ì— ì¶”ê°€
                documents = [doc["content"] for doc in docs]
                metadata = [{"file": "transcript_summary", "title": doc["title"], 
                           "type": doc["type"], "source": "transcript"} for doc in docs]
                self.retrieval_interface.add_documents(documents, metadata)
                
                print(f"ì„±ì í‘œ ìš”ì•½ ì •ë³´ {len(docs)}ê°œ ë¬¸ì„œê°€ RAGì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì„±ì í‘œ RAG ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_rag_search_function(self):
        """RAG ê²€ìƒ‰ í•¨ìˆ˜ ë°˜í™˜"""
        def basic_search(query: str, k: int = 5, **kwargs) -> List[str]:
            return self.retrieval_interface.search_relevant_docs(query, k=k, **kwargs)
        
        return basic_search
    
    def ask_question(self, user_question: str) -> str:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
        
        Args:
            user_question: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            str: ìƒì„±ëœ ë‹µë³€
        """
        try:
            print(f"ì§ˆë¬¸: {user_question}")
            
            # RAG ê²€ìƒ‰ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            rag_search_func = self.get_rag_search_function()
            
            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self.context_builder.create_full_context(
                user_question=user_question,
                transcript_data=self.transcript_data,
                rag_search_func=rag_search_func,
                analysis_result=self.analysis_result,
                include_semester_details=False  # ê¸°ë³¸ ìš”ì•½ë§Œ ì‚¬ìš©
            )
            
            # ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
            messages = [
                {"role": "system", "content": context},
                {"role": "user", "content": user_question}
            ]
            
            # ëª¨ë¸ì„ í†µí•œ ë‹µë³€ ìƒì„±
            response, metadata = self.model_service.generate_response(messages)
            
            # ë¡œê·¸ ì €ì¥
            self.model_service.save_conversation_log(
                user_question=user_question,
                model_response=response,
                metadata=metadata,
                system_prompt=context
            )
            
            return response
            
        except Exception as e:
            error_msg = f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            print(f"{error_msg}")
            return error_msg
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "model_loaded": self.model_service is not None,
            "transcript_loaded": self.transcript_data is not None,
            "analysis_completed": self.analysis_result is not None,
            "rag_available": self.retrieval_interface is not None,
            "components_status": {
                "model_service": self.model_service is not None,
                "document_manager": self.document_manager is not None,
                "retrieval_interface": self.retrieval_interface is not None,
                "context_builder": self.context_builder is not None,
                "academic_analyzer": self.academic_analyzer is not None,
                "summarizer": self.summarizer is not None
            }
        }
    
    def reload_transcript_data(self, new_data_path: str = None):
        """ì„±ì í‘œ ë°ì´í„° ì¬ë¡œë“œ"""
        try:
            if new_data_path:
                with open(new_data_path, 'r', encoding='utf-8') as f:
                    self.transcript_data = json.load(f)
            else:
                self._load_transcript_data()
            
            # ë¶„ì„ ì¬ìˆ˜í–‰
            if self.transcript_data:
                self.analysis_result = self.academic_analyzer.analyze_graduation_requirements(
                    self.transcript_data
                )
            
            print("ì„±ì í‘œ ë°ì´í„° ì¬ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"ì„±ì í‘œ ë°ì´í„° ì¬ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.model_service:
                self.model_service.cleanup()
            print("í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def validate_response(self, question: str, response: str, context_data: Dict) -> Dict[str, Any]:
        """ì‘ë‹µ ê²€ì¦ ë° ì¼ê´€ì„± ì²´í¬"""
        validation_result = {
            "is_valid": True,
            "warnings": [],
            "corrections": []
        }
        
        # ìˆ«ì ì¼ê´€ì„± ì²´í¬
        if "í‰ì " in question or "í•™ì " in question:
            numbers = self.extract_numbers_from_text(response)
            if len(numbers) >= 2:
                # ë¹„êµ ë¬¸ì¥ì—ì„œ ìˆ«ì ìˆœì„œ ì²´í¬
                if "ë” ì¢‹" in response or "ë” ë†’" in response:
                    if numbers[0] < numbers[1] and "ì²« ë²ˆì§¸ê°€ ë”" in response:
                        validation_result["warnings"].append("ìˆ«ì ë¹„êµ ê²°ê³¼ê°€ ëª¨ìˆœë©ë‹ˆë‹¤.")
        
        # ì •ë³´ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
        if "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†" in response or "ì•Œ ìˆ˜ ì—†" in response:
            # ì‹¤ì œë¡œ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            if self.check_info_availability(question, context_data):
                validation_result["warnings"].append("ì‹¤ì œë¡œëŠ” ì •ë³´ê°€ ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return validation_result
    
    def extract_numbers_from_text(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        import re
        numbers = re.findall(r'\d+\.?\d*', text)
        return [float(n) for n in numbers if n]
    
    def check_info_availability(self, question: str, context_data: Dict) -> bool:
        """ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì²´í¬
        if "í•™ê¸°" in question and "ìˆ˜ê°•" in question:
            # ì„±ì í‘œ ë°ì´í„°ì—ì„œ í•´ë‹¹ í•™ê¸° ì •ë³´ í™•ì¸
            transcript_data = context_data.get("transcript_data", {})
            semesters = transcript_data.get("ground_truth", {}).get("semesters", [])
            return len(semesters) > 0
        
        return False


# íŒ©í† ë¦¬ í•¨ìˆ˜
def create_academic_service(model_path: str = None) -> AcademicCounselingService:
    """í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return AcademicCounselingService(model_path)


# ë©”ì¸ ì‹¤í–‰ë¶€
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ë“¤
    from .test_questions import TEST_QUESTIONS
    
    print("í•™ì‚¬ ìƒë‹´ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    service = create_academic_service()
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    status = service.get_system_status()
    print(f"ì‹œìŠ¤í…œ ìƒíƒœ: {status}")
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ ì‹¤í–‰
    test_questions = TEST_QUESTIONS.get("level_1", [])[:3]  # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*50}")
        print(f"í…ŒìŠ¤íŠ¸ {i}: {question}")
        print('='*50)
        
        start_time = time.time()
        response = service.ask_question(question)
        processing_time = time.time() - start_time
        
        print(f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"ì‘ë‹µ: {response}")
    
    # ì •ë¦¬
    service.cleanup()
    print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ") 